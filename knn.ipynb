{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eebdc6-baae-47f9-9e50-dbf70b3adabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# calculate the Euclidean distance between two vectors\n",
    "# Euclidean Distance\n",
    "def euclidean_distance(p, q):\n",
    "    return np.sqrt(np.sum((p - q) ** 2))\n",
    "\n",
    "# Manhattan Distance (L1 Norm)\n",
    "def manhattan_distance(p, q):\n",
    "    return np.sum(np.abs(p - q))\n",
    "\n",
    "# Minkowski Distance\n",
    "def minkowski_distance(p, q, p_value):\n",
    "    return np.sum(np.abs(p - q) ** p_value) ** (1 / p_value)\n",
    "\n",
    "data_set = pd.read_excel(r'c/AIKNN/student_dataset.xlsx')\n",
    "\n",
    "\n",
    "# Define two vectors\n",
    "vector1 = data_set['Previous Semester CGPA'].to_numpy()\n",
    "vector2 = data_set['CGPA'].to_numpy()\n",
    "\n",
    "# Call the function\n",
    "distance = euclidean_distance(vector1, vector2)\n",
    "\n",
    "print(\"Euclidean distance between the two vectors:\", distance)\n",
    "import numpy as np\n",
    "# Define the data\n",
    "data = [\n",
    "    [2.7810836, 2.550537003, 0],\n",
    "    [1.465489372, 2.362125076, 0],\n",
    "    [3.396561688, 4.400293529, 0],\n",
    "    [1.38807019, 1.850220317, 0],\n",
    "    [3.06407232, 3.005305973, 0],\n",
    "    [7.627531214, 2.759262235, 1],\n",
    "    [5.332441248, 2.088626775, 1],\n",
    "    [6.922596716, 1.77106367, 1],\n",
    "    [8.675418651, -0.242068655, 1],\n",
    "    [7.673756466, 3.508563011, 1]\n",
    "]\n",
    "# Convert the data to a numpy array\n",
    "data_np = np.array(data)\n",
    "\n",
    "# Split the data into X and Y\n",
    "X = data_np[:, :2]  # Select all rows and the first two columns\n",
    "Y = data_np[:, 2]   # Select all rows and the third column\n",
    "\n",
    "# Display the X and Y arrays to verify\n",
    "print(\"X array:\")\n",
    "print(X)\n",
    "print(\"\\nY array:\")\n",
    "print(Y)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Separate the data points based on their labels\n",
    "for label in np.unique(Y):\n",
    "    plt.scatter(X[Y == label][:, 0], X[Y == label][:, 1], label=f'Class {int(label)}')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Scatter Plot of Data Points')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "from collections import Counter\n",
    "# kNN algorithm\n",
    "def k_nearest_neighbors(X, Y, query_point, k):\n",
    "    distances = []\n",
    "\n",
    "    # Calculate distances from the query point to all other points\n",
    "    for i, point in enumerate(X):\n",
    "        distance = euclidean_distance(point, query_point)\n",
    "        distances.append((distance, Y[i]))\n",
    "\n",
    "    # Sort distances in ascending order\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Select the k nearest neighbors\n",
    "    k_nearest = distances[:k]\n",
    "\n",
    "    # Get the labels of the k nearest neighbors\n",
    "    k_nearest_labels = [label for _, label in k_nearest]\n",
    "\n",
    "    # Determine the most common label (majority vote)\n",
    "    majority_vote = Counter(k_nearest_labels).most_common(1)\n",
    "\n",
    "    return majority_vote[0][0]\n",
    "\n",
    "# Define a query point\n",
    "query_point = np.array([7.0, 3.0])\n",
    "\n",
    "# Set the value of k\n",
    "k = 3\n",
    "\n",
    "# Predict the class for the query point\n",
    "predicted_class = k_nearest_neighbors(X, Y, query_point, k)\n",
    "\n",
    "print(f\"The predicted class for the query point {query_point} is: {predicted_class}\")\n",
    "# Method to plot the data\n",
    "def plot_data(X, Y, query_point=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Separate the data points based on their labels\n",
    "    for label in np.unique(Y):\n",
    "        plt.scatter(X[Y == label][:, 0], X[Y == label][:, 1], label=f'Class {int(label)}')\n",
    "\n",
    "    # Plot the query point if provided\n",
    "    if query_point is not None:\n",
    "        plt.scatter(query_point[0], query_point[1], c='red', marker='x', s=100, label='Query Point')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.title('Scatter Plot of Data Points')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Define the dataset\n",
    "X = np.array([\n",
    "    [2.7810836, 2.550537003],\n",
    "    [1.465489372, 2.362125076],\n",
    "    [3.396561688, 4.400293529],\n",
    "    [1.38807019, 1.850220317],\n",
    "    [3.06407232, 3.005305973],\n",
    "    [7.627531214, 2.759262235],\n",
    "    [5.332441248, 2.088626775],\n",
    "    [6.922596716, 1.77106367],\n",
    "    [8.675418651, -0.242068655],\n",
    "    [7.673756466, 3.508563011]\n",
    "])\n",
    "\n",
    "Y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Define a query point\n",
    "query_point = np.array([3.0, 3.0])\n",
    "\n",
    "# Set the value of k\n",
    "k = 3\n",
    "\n",
    "# Predict the class for the query point\n",
    "predicted_class = k_nearest_neighbors(X, Y, query_point, k)\n",
    "print(f\"The predicted class for the query point {query_point} is: {predicted_class}\")\n",
    "\n",
    "# Plot the data with the query point\n",
    "plot_data(X, Y, query_point)\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the path to the CSV file\n",
    "file_path = r'/content/drive/MyDrive/AIKNN/student_dataset.xlsx'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "data_2C = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the data is loaded correctly\n",
    "print(data_2C.head())\n",
    "data_2C.describe().transpose()\n",
    "data_2C.dtypes\n",
    "colnames_numeric = data_2C.columns[1:6]\n",
    "#Scaling a data in always a good idea while using KNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_2C[colnames_numeric] = scaler.fit_transform(data_2C[colnames_numeric])\n",
    "\n",
    "data_2C.head()\n",
    "data_2C.shape\n",
    "df = data_2C.values.tolist()\n",
    "#Breaking the data into training and test set\n",
    "import random\n",
    "def train_test_split(data, split, trainingSet = [], testSet = []):\n",
    "    for x in range(len(data)):\n",
    "        if random.random() < split:\n",
    "            trainingSet.append(data[x])\n",
    "        else:\n",
    "            testSet.append(data[x])\n",
    "\n",
    "trainingSet = []\n",
    "testSet = []\n",
    "split = 0.66\n",
    "train_test_split(df, split, trainingSet, testSet)\n",
    "len(trainingSet)\n",
    "len(testSet)\n",
    "#Define Euclidean distances\n",
    "import math\n",
    "def Euclideandist(x,xi, length, start_index=1):\n",
    "    d = 0.0\n",
    "    for i in range(start_index, length + start_index):\n",
    "        d += pow(float(x[i])- float(xi[i]),2)\n",
    "    return math.sqrt(d)\n",
    "#Getting the K neighbours having the closest Euclidean distance to the test instance\n",
    "import operator\n",
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance)-2\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = Euclideandist(testInstance, trainingSet[x], length, start_index=1)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "#After sorting the neighbours based on their respective classes, max voting to give the final class of the test instance\n",
    "import operator\n",
    "def getResponse(neighbors):\n",
    "\tclassVotes = {}\n",
    "\tfor x in range(len(neighbors)):\n",
    "\t\tresponse = neighbors[x][-1]\n",
    "\t\tif response in classVotes:\n",
    "\t\t\tclassVotes[response] += 1\n",
    "\t\telse:\n",
    "\t\t\tclassVotes[response] = 1\n",
    "\tsortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)#Sorting it based on votes\n",
    "\treturn sortedVotes[0][0] #Please note we need the class for the top voted class, hence [0][0]#\n",
    "#Getting the accuracy\n",
    "def getAccuracy(testSet, predictions):\n",
    "\tcorrect = 0\n",
    "\tfor x in range(len(testSet)):\n",
    "\t\tif testSet[x][-1] == predictions[x]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn (correct/float(len(testSet))) * 100.0\n",
    "\t# generate predictions\n",
    "predictions=[]\n",
    "k = 3\n",
    "for x in range(len(testSet)):\n",
    "    neighbors = getNeighbors(trainingSet, testSet[x], k)\n",
    "    result = getResponse(neighbors)\n",
    "    predictions.append(result)\n",
    "    print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][-1]))\n",
    "\n",
    "accuracy = getAccuracy(testSet, predictions)\n",
    "print('Accuracy: ' + repr(accuracy) + '%')\n",
    "#Implementing Naive Bayes using scikitlearn\n",
    "trainingSet2 = pd.DataFrame(np.array(trainingSet).reshape(len(trainingSet),7), columns = data_2C.columns)\n",
    "testSet2 = pd.DataFrame(np.array(testSet).reshape(len(testSet),7), columns = data_2C.columns)\n",
    "trainingSet2.head()\n",
    "\n",
    "trainingSet2.dtypes\n",
    "#Even the numeric terms have been converted into an object. Hence need to reconvert\n",
    "trainingSet2[colnames_numeric] = trainingSet2[colnames_numeric].apply(pd.to_numeric, errors = 'coerce', axis = 0)\n",
    "trainingSet2.dtypes\n",
    "\n",
    "testSet2[colnames_numeric] = testSet2[colnames_numeric].apply(pd.to_numeric, errors = 'coerce', axis = 0)\n",
    "testSet2.dtypes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "num_bins = 3\n",
    "x_train = trainingSet2.select_dtypes(include=['number']).drop('CGPA', axis=1)\n",
    "x_test = testSet2.select_dtypes(include=['number']).drop('CGPA', axis=1)\n",
    "y_train = pd.cut(trainingSet2['CGPA'], bins=num_bins, labels=False)\n",
    "y_test = pd.cut(testSet2['CGPA'], bins=num_bins, labels=False)\n",
    "knn.fit(x_train, y_train)\n",
    "prediction = knn.predict(x_test)\n",
    "print('Prediction: {}'.format(prediction))\n",
    "print('With KNN (K=3) accuracy is: ',knn.score(x_test,y_test)) # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732cb0a0-485e-4cb5-ae1f-d0643528e712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37c813-36d8-4299-b336-5c80ee66e97d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae7bb8-9035-4ddb-b00c-06539defef81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
